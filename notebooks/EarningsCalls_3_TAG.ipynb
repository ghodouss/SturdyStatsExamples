{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be88a0d9-04c3-4596-9a10-53013eb8f2cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install sturdy-stats-sdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d844468-aa26-4b48-a1a5-9cc1c8fc1a28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pip install sturdy-stats-sdk pandas numpy plotly\n",
    "\n",
    "from sturdystats import Index, Job\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from plotly import express as px\n",
    "import openai\n",
    "import json\n",
    "\n",
    "\n",
    "API_KEY = \"PublicIndex_NoKeyNeeded\" # Replace with your own Api Key to query your own indices\n",
    "index_id = \"index_05a7cb07da764f0f81397b39ce65ab06\" ## Optionally Replace with your own if you want\n",
    "OPENAI_API_KEY= \"XXX\"\n",
    "\n",
    "gpt = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "index = Index(API_key=API_KEY, id=index_id)\n",
    "\n",
    "quarter = \"2024Q4\"\n",
    "prevquarter = \"2024Q3\"\n",
    "ticker = \"GOOG\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efe0efb4-e91e-492a-ba99-ec69546d1465",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Section 1: Single Document Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d285a74-b28b-47d9-a7c5-559d31cb5ff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Latest Earnings Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619b0410-476f-4930-b0b3-bbe4d2497e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "getcall = lambda q, t: index.query(filters=f\"quarter='{q}' AND ticker='{t}'\", context=100000, limit=1)[\"docs\"][0][\"text\"]\n",
    "latest_earnings_call = getcall(quarter, ticker)\n",
    "\n",
    "print(latest_earnings_call[:1000])\n",
    "print(\"...\")\n",
    "print(latest_earnings_call[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43245f3c-953d-4725-aad6-8efdb0945897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31e750a0-2ec2-40ad-9336-5d58422e6422",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Helper Function\n",
    "\n",
    "This function helps track the cost of our input on output tokens for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17abd9bd-a4f7-415c-a115-15a4dc95efed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "COSTS = {\n",
    "  \"gpt-4o-mini\": [ .15/1e6, .6/1e6],\n",
    "  \"gpt-4o\": [2.5/1e6, 10/1e6]\n",
    "}\n",
    "def basicGPT(prompt, model=\"gpt-4o-mini\", response_format={\"type\":\"json_object\"}):\n",
    "  res = gpt.chat.completions.create(\n",
    "    model=model,\n",
    "    response_format=response_format,\n",
    "    messages=[{\"role\": \"user\", \"content\":prompt}]\n",
    "  )\n",
    "  pt, ct = res.usage.prompt_tokens, res.usage.completion_tokens\n",
    "  cost = pt*COSTS[model][0] + ct*COSTS[model][1]\n",
    "\n",
    "  res = res.choices[0].message.content\n",
    "  if response_format is not None:\n",
    "    res = json.loads(res)\n",
    "  return res, pt+ct, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3df876c6-193e-4964-bec4-93697af83b90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Basic Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0672475b-be7d-476d-9d9a-a27ff247ad46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an financial analysts.\n",
    "You have been given an earnings call from {ticker}'s {quarter}.\n",
    "Provide a summary with excerpts extracted from the earnings call. \n",
    "Provide the summary in a json file under the key 'summary'. The summary itself should be a single formatted string containing structured bullet points. This summary can be relatively verbose. Pull out anything that is interesting with examples. Be as specific as possible\n",
    "\n",
    "EARNINGS CALL\n",
    "{latest_earnings_call}\n",
    "\"\"\"\n",
    "res, tokens, cost = basicGPT(prompt, model=\"gpt-4o\")\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a5e9b9e-d133-44d5-bc6b-08e5dc9358af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(res[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7316a409-eacb-4826-9844-a8bd1e51f5bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sturdy Statistical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e95bac2-8a7b-44e2-b22c-bbf47893bd3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Topic Diff cuts through the noise\n",
    "The topic diff api compares the dataset selected by q1 (in this case, google's latest earnings call) to a second specified subset (if none provided, it uses dataset as a whole). This has the effect of automatically eliminating basic boilerplate parts of the conversation and pulling out the most distinct topical content in the call. It also opens the door to complex quantitative comparison which enables granular, use controlled summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6c42b0d-6f2a-45b2-a8a8-f6e7ee4cfbd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(index.topicDiff(f\"quarter='{quarter}' AND ticker='{ticker}'\", cutoff=1.0, limit=100)[\"topics\"])\n",
    "df = df.sort_values([\"confidence\", \"prevalence\"], ascending=False)\n",
    "df[[\"topic_id\", \"short_title\", \"prevalence\", \"confidence\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ee0ea54-9c41-46ac-b809-a9ab5a04c9fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Extractive Summaries\n",
    "Our topic diff provides a high level list of topics. For GPT outputs, this is often where analysis ends. With Sturdy Statistics, a topic is just the beginning.\n",
    "\n",
    "We can extract all the excerpts that are associated any one or multiple topics. We can perform this extraction on the corpus as a whole, or, in this case, on a single document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ead609-25f3-4c45-877a-4f98b421c905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "row = df.sample()\n",
    "docs = index.query(topic_id=row.topic_id, filters=f\"quarter='{quarter}' AND ticker='{ticker}'\")[\"docs\"]\n",
    "print(row.short_title)\n",
    "for doc in docs:\n",
    "  print(doc[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "041ed972-6992-4490-a8a0-78ef3ffba756",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Synergy\n",
    "We can combine our topic diff meta analysis with our granlular extractions to power what we call a __Topic Augmented Retrieval__ or __TAG__ for short. \n",
    "\n",
    "__TAG__ enables us to get statistically driven summaries at a fraction of the cost of GPT. Instead of using gpt for extraction, analysis, and formatting, we now can use it exclusively as a formatting engine. This enables us to both reduce our input token count AND use smaller, cheaper llms while getting more complete and arguably better results.\n",
    "\n",
    "Unlike the previous GPT centered approach, we have full visibility over the actual data and can easily fact check and cite the inputs. It is important to note that while RAG also enables this fact checking, __we cannot perform RAG on this task because there is no input query__. \n",
    "\n",
    "We will compare TAG to RAG in Sections (2, 3) on a set of problems more adapted to RAG use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c127ab-5ba5-4916-93cd-14f79f490d1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def summarizeRow(row):\n",
    "  topic_id = row['topic_id']\n",
    "  docs = index.query(topic_id=topic_id, filters=f\"quarter='{quarter}' AND ticker='{ticker}'\", override_args=dict(max_excerpts_per_doc=5))[\"docs\"]\n",
    "  text = \"\\n-\\n\".join([doc['text'] for doc in docs])\n",
    "  prompt = f\"\"\"You are an financial analysts.\n",
    "  You have been given a set of EXCERPTS from {ticker}'s {quarter} earnings calls. \n",
    "  These excerpts pertain to row['short_title']. Summarize on the content relevant to the row['short_title'].\n",
    "  Provide a short_title and a brief summary for the EXCERPTS provided below.\n",
    "  Return the output in valid json dictionary containing the keys short_title and summary.\n",
    "\n",
    "  EXCERPTS\n",
    "  {text}\n",
    "  \"\"\"\n",
    "  res, tokens, cost = basicGPT(prompt)\n",
    "  res[\"examples\"] = text\n",
    "  res[\"cost\"] = cost \n",
    "  res[\"tokens\"] = tokens\n",
    "  return res\n",
    "\n",
    "summaries = [ summarizeRow(row) for row in df.to_dict(\"records\") ]\n",
    "for key in [\"summary\", \"examples\", \"cost\", \"tokens\"]:\n",
    "  df[key] = [ s[key] for s in summaries ]\n",
    "\n",
    "print(\"Tokens:\", df.tokens.sum())\n",
    "print(\"Cost:\", df.cost.sum())\n",
    "\n",
    "for row in df.to_dict(\"records\"):\n",
    "  print(row[\"short_title\"])\n",
    "  print(\"Prevalence:\", row[\"prevalence\"])\n",
    "  print(\"Topic Id:\", row[\"topic_id\"])\n",
    "  print(row[\"summary\"])\n",
    "  #print(s[\"examples\"])\n",
    "  print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3598de3e-ab4e-4def-9a89-54a086719ea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "  print(d[\"text\"])\n",
    "  print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f65dfc2-fb99-4571-be37-c261fc277ea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Recursive Summaries\n",
    "If you want an even high level report, you add one more layer of summarization above the previous report. Because we have deeply simplified our prompts to gpt asking it only to rephrase excerpts rather than find them itself, the gpt summaries are much more reliable and are more amenable to recursive use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a8831ab-469c-49af-8b0a-bc22f5240f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def summarizeSummaries(df):\n",
    "  text = [ f\"TITLE: {row['short_title']}\\nPREVALENCE: {row['prevalence']}\\nSUMMARY: {row['summary']}\" for row in df.to_dict(\"records\") ]\n",
    "  prompt = f\"\"\"You are an financial analysts.\n",
    "  You have been given a set of summaries from {ticker}'s {quarter} earnings calls. \n",
    "  Each summary has been given a title, a prevalence which describes the percentage of the call that summary entails and a summary.\n",
    "  Given the information in the TITLE, PREVALANCE and SUMMARY fields provided about the earnings call, provide a structured overview of the events of the past quarter. \n",
    "  Provide the summary in a json file under the key 'summary'. The summary itself should be a single formatted string a 1-3 paragraphs. This summary can be relatively verbose. Pull out anything that is interesting with examples. Be as specific as possible.\n",
    "\n",
    "  EXCERPTS\n",
    "  {text}\n",
    "  \"\"\"\n",
    "  return basicGPT(prompt)\n",
    "res, tokens, cost = summarizeSummaries(df)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Cost:\", cost)\n",
    "\n",
    "print(\"OVERVIEW\")\n",
    "print(res[\"summary\"])\n",
    "print(\"-\"*50, \"\\n\")\n",
    "for row in df.to_dict(\"records\"):\n",
    "  print(row[\"short_title\"])\n",
    "  print(\"Topic Id:\", row[\"topic_id\"])\n",
    "  print(row[\"summary\"])\n",
    "  #print(s[\"examples\"])\n",
    "  print(\"-\"*20, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e2986dc-a722-432c-b5df-04d04d14571d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 2: Trends over Time\n",
    "\n",
    "In the above report, topic 87 (AI in Consumer Devices) caught my eye.\n",
    "\n",
    "```\n",
    "AI in Consumer Devices\n",
    "Topic Id: 87\n",
    "During the Q4 earnings call, Google discussed its ongoing efforts to enhance the performance and capabilities of its AI models, particularly the Gemini models, which are now utilized across all major products with over 2 billion monthly users, including Google Maps. The company announced plans to introduce advanced AI experiences, particularly through Project Astra, by 2025. Additionally, Gemini is being made available to developers, as highlighted by its integration with GitHub Copilot. Google is restructuring its teams to improve agility in deploying new models, including moving the Gemini app team to Google DeepMind. These changes aim to streamline operations and accelerate advancements in AI technologies.\n",
    "```\n",
    "\n",
    "I want to understand how Google's approach/results with respect to consumer devices has transformed over the past few quarters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c5ea36-b53a-48e4-98f3-25c584fe0226",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2676132b-56ab-46e8-9b54-976cfa5c8ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "docs = index.query(filters=\"ticker='GOOG'\", context=100000, sort_by=\"quarter\")[\"docs\"]\n",
    "quarters = [ d[\"metadata\"][\"quarter\"] for d in docs ]\n",
    "print(quarters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8438f241-7d90-4d2f-9d20-ffdbea5a8e26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeaf0129-97eb-4809-9b3c-498b1c42639e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "text = \"\\n\\n---------\\n\\n\".join([ f\"QUARTER: {d['metadata']['quarter']}\\nCONTENT: {d['text']}\" for d in docs ])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an financial analysts.\n",
    "You have been given Google's earnings call from the following quarters: {quarters}.\n",
    "We are interested in understanding how Google's approach to `AI IN CONSUMER DEVICES` has changed over quarters.\n",
    "Provide an overview and a quarter by quarter summary of how this approach has changed.\n",
    "\n",
    "Each earnings call has the following Structures:\n",
    "QUARTER: 2024Q1\n",
    "CONTENT: The full content of the earnings call\n",
    "This field will be very long.\n",
    "\n",
    "Provide the summary in a json file under the key 'summary'. The summary itself should be a single formatted string containing structured bullet points. This summary can be relatively verbose. Pull out anything that is interesting with examples. Be as specific as possible\n",
    "\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "res, tokens, cost = basicGPT(prompt, model=\"gpt-4o\")\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9534d814-cfe8-4015-9a0e-7d6061c89930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(res[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfa0fb68-ba07-4fd8-b73b-ea9b41901878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### GPT"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "EarningsCalls_3_TAG",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
